{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 2: finding the best parameters for predicting the fare of taxi rides\n",
    "We return to our Random Forest Regression and want to automatically optimize all free parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data we have saved after wrangling and pre-processing in block I\n",
    "X=pd.read_csv('../../DATA/train_cleaned.csv')\n",
    "drop_columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','key','pickup_datetime','pickup_date','pickup_latitude_round3','pickup_longitude_round3','dropoff_latitude_round3','dropoff_longitude_round3']\n",
    "X=X.drop(drop_columns,axis=1)\n",
    "X=pd.get_dummies(X)# one hot coding\n",
    "#generate labels\n",
    "y=X['fare_amount']\n",
    "X=X.drop(['fare_amount'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Optimize\n",
    "Scikit Optimize (https://scikit-optimize.github.io/stable/index.html) is a AutoML toolbox wrapped around Scikit-Learn. It allows us to use state-of-the-art automatic hyper-parameter optimization on top of our learning algorithms.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.17.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
     ]
    }
   ],
   "source": [
    "# install \n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E 2.1 Bayesian Optimization of a Random Forest Regression Model\n",
    "use Bayesian Optimization with Cross-Validation (https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV) to find the best regression model. Compare\n",
    "* linear regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) \n",
    "* Random Forest regression (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "* and SVM regression (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)\n",
    "\n",
    "NOTES: this can become quite compute intensive! Hence,\n",
    "* use a smaller subset of the training data to run the experiments \n",
    "* think about the range of your parameters (e.g. larger number of trees in RF or high C-values in SMV will make models expensive)\n",
    "* optimize only the following parameters per model type:\n",
    "    * linear: no parameters to optimize\n",
    "    * RF: #trees and depth\n",
    "    * SVM: C and gamma (use RBF kernel)\n",
    "* parallelize -> n_jobs\n",
    "* use CoLab to rum the job for up to 12h \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.01, random_state=0)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "optSVC = BayesSearchCV(\n",
    "    SVR(kernel='rbf'),\n",
    "    {\n",
    "        'C': Real(1e-3, 1e3),#, prior='log-uniform'),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    n_iter=32,\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# executes bayesian optimization\n",
    "_ = optSVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6572228144556258\n"
     ]
    }
   ],
   "source": [
    "# model can be saved, used for predictions or scoring\n",
    "print(optSVC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('C', 97.36142832341862), ('gamma', 'auto')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optSVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "mySVR = SVR(kernel='rbf', gamma='auto', C=97.36142832341862)\n",
    "\n",
    "mySVR.fit(X_train, y_train)\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(mySVR, 'mySVR0.1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "mySVR = load('mySVR0.1.joblib')\n",
    "\n",
    "y_train_predSVR = mySVR.predict(X_train)\n",
    "y_test_predSVR = mySVR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.58636471868495"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_train, y_train_predSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.2940772129688"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_test_predSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.01, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "optRFR = BayesSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    {\n",
    "        'n_estimators': Integer(10, 1000),\n",
    "        'max_depth': Integer(3, 30),\n",
    "    },\n",
    "    n_iter=32,\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# executes bayesian optimization\n",
    "_ = optRFR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model can be saved, used for predictions or scoring\n",
    "print(optRFR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optRFR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "myRFR = RandomForestRegressor(n_estimators = 639, max_depth=6, n_jobs=-1)\n",
    "\n",
    "myRFR.fit(X_train, y_train)\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(myRFR, 'myRFR.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "myRFR = load('myRFR.joblib')\n",
    "\n",
    "y_train_predRFR = myRFR.predict(X_train)\n",
    "y_test_predRFR = myRFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.776169173548443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_train, y_train_predRFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.49330474971364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_test_predRFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 229 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinReg = LinearRegression(n_jobs=-1)\n",
    "\n",
    "LinReg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_predLinReg = LinReg.predict(X_train)\n",
    "\n",
    "y_test_predLinReg = LinReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.44901729209009"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_train, y_train_predLinReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.393393042065448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_test_predLinReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
